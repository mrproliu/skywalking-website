<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Apache SkyWalking – Performance</title>
    <link>/tags/performance/</link>
    <description>Recent content in Performance on Apache SkyWalking</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 27 Sep 2022 00:00:00 +0000</lastBuildDate>
    
	  <atom:link href="/tags/performance/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Blog: Diagnose Service Mesh Network Performance with eBPF</title>
      <link>/blog/diagnose-service-mesh-network-performance-with-ebpf/</link>
      <pubDate>Tue, 27 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/diagnose-service-mesh-network-performance-with-ebpf/</guid>
      <description>
        
        
        &lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;This article will show how to use &lt;a href=&#34;https://github.com/apache/skywalking&#34;&gt;Apache SkyWalking&lt;/a&gt; with &lt;a href=&#34;https://ebpf.io/what-is-ebpf/&#34;&gt;eBPF&lt;/a&gt; to make network troubleshooting easier in a service mesh environment.&lt;/p&gt;
&lt;p&gt;Apache SkyWalking is an application performance monitor tool for distributed systems. It observes metrics, logs, traces, and events in the service mesh environment and uses that data to generate a dependency graph of your pods and services. This dependency graph can provide quick insights into your system, especially when there&amp;rsquo;s an issue.&lt;/p&gt;
&lt;p&gt;However, when troubleshooting network issues in SkyWalking&amp;rsquo;s service topology, it is not always easy to pinpoint where the error actually is. There are two reasons for the difficulty:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Traffic through the Envoy sidecar is not easy to observe.&lt;/strong&gt; Data from Envoy&amp;rsquo;s &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/api-v3/service/accesslog/v3/als.proto&#34;&gt;Access Log Service (ALS)&lt;/a&gt; shows traffic between services (sidecar-to-sidecar), but not metrics on communication between the Envoy sidecar and the service it proxies. Without that information, it is more difficult to understand the impact of the sidecar.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;There is a lack of data from transport layer (OSI Layer 4) communication.&lt;/strong&gt; Since services generally use application layer (OSI Layer 7) protocols such as HTTP, observability data is generally restricted to application layer communication. However, the root cause may actually be in the transport layer, which is typically opaque to observability tools.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Access to metrics from Envoy-to-service and transport layer communication can make it easier to diagnose service issues. To this end, SkyWalking needs to collect and analyze transport layer metrics between processes inside Kubernetes pods - a task well suited to eBPF. We investigated using eBPF for this purpose and present our results and
a demo below.&lt;/p&gt;
&lt;h2 id=&#34;monitoring-kubernetes-networks-with-ebpf&#34;&gt;Monitoring Kubernetes Networks with eBPF&lt;/h2&gt;
&lt;p&gt;With its origins as the Extended Berkeley Packet Filter, eBPF is a general purpose mechanism for injecting and running your own code into the Linux kernel and is an excellent tool for monitoring network traffic in Kubernetes Pods. In the next few sections, we&#39;ll provide an overview of how to use eBPF for network monitoring as background for introducing &lt;a href=&#34;https://github.com/apache/skywalking-rover&#34;&gt;Skywalking Rover&lt;/a&gt;, a metrics collector and profiler powered by eBPF to diagnose CPU and network performance.&lt;/p&gt;
&lt;h3 id=&#34;how-applications-and-the-network-interact&#34;&gt;How Applications and the Network Interact&lt;/h3&gt;
&lt;p&gt;Interactions between the application and the network can generally be
divided into the following steps from higher to lower levels of
abstraction:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f0.svg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;User Code:&lt;/strong&gt; Application code uses high-level network libraries in the application stack to exchange data across the network, like sending and receiving HTTP requests.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Network Library:&lt;/strong&gt; When the network library receives a network request, it interacts with the language API to send the network data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Language API:&lt;/strong&gt; Each language provides an API for operating the network, system, etc. When a request is received, it interacts with the system API. In Linux, this API is called syscalls.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Linux API:&lt;/strong&gt; When the Linux kernel receives the request through the API, it communicates with the socket to send the data, which is usually closer to an OSI Layer 4 protocol, such as TCP, UDP, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Socket Ops:&lt;/strong&gt; Sending or receiving the data to/from the NIC.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Our hypothesis is that eBPF can monitor the network. There are two ways
to implement the interception: &lt;strong&gt;User space (uprobe)&lt;/strong&gt; or &lt;strong&gt;Kernel space
(kprobe)&lt;/strong&gt;. The table below summarizes the differences.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Pros&lt;/th&gt;
&lt;th&gt;Cons&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;uprobe&lt;/td&gt;
&lt;td&gt;•	Get more application-related contexts, such as whether the current request is HTTP or HTTPS.&lt;/br&gt;•	Requests and responses can be intercepted by a single method&lt;/td&gt;
&lt;td&gt;•	Data structures can be unstable, so it is more difficult to get the desired data. &lt;/br&gt; •	Implementation may differ between language/library versions. &lt;/br&gt; •	Does not work in applications without &lt;a href=&#34;https://en.wikipedia.org/wiki/Symbol_table&#34;&gt;symbol tables&lt;/a&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kprobe&lt;/td&gt;
&lt;td&gt;•	Available for all languages. &lt;/br&gt; •	The data structure and methods are stable and do not require much adaptation. &lt;/br&gt; •	Easier correlation with underlying data, such as getting the destination address of TCP, OSI Layer 4 protocol metrics, etc.&lt;/td&gt;
&lt;td&gt;•	A single request and response may be split into multiple probes. &lt;/br&gt; •	Contextual information is not easy to get for stateful requests. For example header compression in HTTP/2.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For the general network performance monitor, we chose to use the kprobe (intercept the syscalls) for the following reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It&amp;rsquo;s available for applications written in any programming language, and it&amp;rsquo;s stable, so it saves a lot of development/adaptation costs.&lt;/li&gt;
&lt;li&gt;It can be correlated with metrics from the system level, which makes it easier to troubleshoot.&lt;/li&gt;
&lt;li&gt;As a single request and response are split into multiple probes, we can use technology to correlate them.&lt;/li&gt;
&lt;li&gt;For contextual information, It&amp;rsquo;s usually used in OSI Layer 7 protocol network analysis. So, if we just monitor the network performance, then they can be ignored.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;kprobes-and-network-monitoring&#34;&gt;Kprobes and network monitoring&lt;/h3&gt;
&lt;p&gt;Following the &lt;a href=&#34;http://linasm.sourceforge.net/docs/syscalls/network.php&#34;&gt;network syscalls of Linux documentation&lt;/a&gt;, we can implement network monitoring by intercepting two types of methods: &lt;strong&gt;socket operations&lt;/strong&gt; and &lt;strong&gt;send/receive&lt;/strong&gt; methods.&lt;/p&gt;
&lt;h4 id=&#34;socket-operations&#34;&gt;Socket Operations&lt;/h4&gt;
&lt;p&gt;When accepting or connecting with another socket, we can get the
following information:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Connection information&lt;/strong&gt;: Includes the remote address from the connection which helps us to understand which pod is connected.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Connection statics:&lt;/strong&gt; Includes basic metrics from sockets, such as round-trip time (&lt;a href=&#34;https://en.wikipedia.org/wiki/Round-trip_delay&#34;&gt;RTT&lt;/a&gt;), lost packet count in TCP, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Socket and file descriptor (&lt;a href=&#34;https://en.wikipedia.org/wiki/File_descriptor&#34;&gt;FD&lt;/a&gt;) mapping:&lt;/strong&gt; Includes the relationship between the Linux file descriptor and socket object. It is useful when sending and receiving data through a Linux file descriptor.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;sendreceive&#34;&gt;Send/Receive&lt;/h4&gt;
&lt;p&gt;The interface related to sending or receiving data is the focus of
performance analysis. It mainly contains the following parameters:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Socket file descriptor:&lt;/strong&gt; The file descriptor of the current operation corresponding to the socket.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Buffer:&lt;/strong&gt; The data sent or received, passed as a byte array.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Based on the above parameters, we can analyze the following data:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Bytes:&lt;/strong&gt; The size of the packet in bytes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Protocol:&lt;/strong&gt; The protocol analysis according to the buffer data, such as HTTP, MySQL, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Execution Time:&lt;/strong&gt; The time it takes to send/receive the data.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point (Figure 1) we can analyze the following steps for the
whole lifecycle of the connection:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Connect/Accept:&lt;/strong&gt; When the connection is created.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transform:&lt;/strong&gt; Sending and receiving data on the connection.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Close:&lt;/strong&gt; When the connection is closed.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;f1.svg&#34; alt=&#34;Figure 1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Figure 1&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;protocol-and-tls&#34;&gt;Protocol and TLS&lt;/h3&gt;
&lt;p&gt;The previous section described how to analyze connections using send or receive buffer data. For example, following the &lt;a href=&#34;https://www.rfc-editor.org/rfc/rfc2068.html#section-4.1&#34;&gt;HTTP/1.1 message specification&lt;/a&gt; to analyze the connection. However, this does not work for TLS requests/responses.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f2.svg&#34; alt=&#34;Figure 2&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Figure 2&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;When TLS is in use, the Linux Kernel transmits data encrypted in user space. In the figure above, The application usually transmits SSL data through a third-party library (such as OpenSSL). For this case, the Linux API can only get the encrypted data, so it cannot recognize any higher layer protocol. To decrypt inside eBPF, we need to follow these steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Read unencrypted data through uprobe:&lt;/strong&gt; Compatible multiple languages, using uprobe to capture the data that is not encrypted before sending or after receiving. In this way, we can get the original data and associate it with the socket.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Associate with socket:&lt;/strong&gt; We can associate unencrypted data with the socket.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;openssl-use-case&#34;&gt;OpenSSL Use case&lt;/h4&gt;
&lt;p&gt;For example, the most common way to send/receive SSL data is to use OpenSSL as a shared library, specifically the &lt;a href=&#34;https://www.openssl.org/docs/man1.1.1/man3/SSL_read.html&#34;&gt;SSL_read&lt;/a&gt; and &lt;a href=&#34;https://www.openssl.org/docs/man1.1.1/man3/SSL_write.html&#34;&gt;SSL_write&lt;/a&gt; methods to submit the buffer data with the socket.&lt;/p&gt;
&lt;p&gt;Following the &lt;a href=&#34;https://www.openssl.org/docs/man1.1.1/man7/ssl.html&#34;&gt;documentation&lt;/a&gt;, we can intercept these two methods, which are almost identical to the API in Linux. The source code of the SSL structure in OpenSSL shows that the &lt;a href=&#34;https://github.com/openssl/openssl/blob/9eae491721209f302a9a475bffd271370e8bcb8f/crypto/bio/bio_local.h#L115-L125&#34;&gt;Socket FD&lt;/a&gt; exists in the &lt;a href=&#34;https://github.com/openssl/openssl/blob/9eae491721209f302a9a475bffd271370e8bcb8f/ssl/ssl_local.h#L1068-L1083&#34;&gt;BIO object of the SSL structure&lt;/a&gt;, and we can get it by the offset.&lt;/p&gt;
&lt;p&gt;In summary, with knowledge of how OpenSSL works, we can read unencrypted data in an eBPF function.&lt;/p&gt;
&lt;h2 id=&#34;introducing-skywalking-rover-an-ebpf-based-metrics-collector-and-profiler&#34;&gt;Introducing SkyWalking Rover, an eBPF-based Metrics Collector and Profiler&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/apache/skywalking-rover&#34;&gt;SkyWalking Rover&lt;/a&gt; introduces the eBPF network profiling feature into the SkyWalking ecosystem. It&amp;rsquo;s currently supported in a Kubernetes environment, so must be deployed inside a Kubernetes cluster. Once the deployment is complete, SkyWalking Rover can monitor the network for all processes inside a given Pod. Based on the monitoring data, SkyWalking can generate the topology relationship diagram and metrics between processes.&lt;/p&gt;
&lt;h3 id=&#34;topology-diagram&#34;&gt;Topology Diagram&lt;/h3&gt;
&lt;p&gt;The topology diagram can help us understand the network access between processes inside the same Pod, and between the process and external environment (other Pod or service). Additionally, it can identify the data direction of traffic based on the line flow direction.&lt;/p&gt;
&lt;p&gt;In Figure 3 below, all nodes within the hexagon are the internal process of a Pod, and nodes outside the hexagon are externally associated services or Pods. Nodes are connected by lines, which indicate the direction of requests or responses between nodes (client or server). The protocol is indicated on the line, and it&amp;rsquo;s either HTTP(S), TCP, or TCP(TLS). Also, we can see in this figure that the line between Envoy and Python applications is bidirectional because Envoy intercepts all application traffic.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f3.jpg&#34; alt=&#34;Figure 3&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Figure 3&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;metrics&#34;&gt;Metrics&lt;/h3&gt;
&lt;p&gt;Once we recognize the network call relationship between processes through the topology, we can select a specific line and view the TCP metrics between the two processes.&lt;/p&gt;
&lt;p&gt;The diagram below (Figure 4) shows the metrics of network monitoring between two processes. There are four metrics in each line. Two on the left side are on the client side, and two on the right side are on the server side. If the remote process is not in the same Pod, only one side of the metrics is displayed.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f4.jpg&#34; alt=&#34;Figure 4&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Figure 4&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The following two metric types are available:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Counter:&lt;/strong&gt; Records the total number of data in a certain period. Each counter contains the following data:
a.  &lt;strong&gt;Count:&lt;/strong&gt; Execution count.
b.  &lt;strong&gt;Bytes:&lt;/strong&gt; Packet size in bytes.
c.  &lt;strong&gt;Execution time:&lt;/strong&gt; Execution duration.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Histogram:&lt;/strong&gt; Records the distribution of data in the buckets.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Based on the above data types, the following metrics are exposed:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th&gt;Unit&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Write&lt;/td&gt;
&lt;td&gt;Counter and histogram&lt;/td&gt;
&lt;td&gt;Millisecond&lt;/td&gt;
&lt;td&gt;The socket write counter.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read&lt;/td&gt;
&lt;td&gt;Counter and histogram&lt;/td&gt;
&lt;td&gt;Millisecond&lt;/td&gt;
&lt;td&gt;The socket read counter.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Write RTT&lt;/td&gt;
&lt;td&gt;Counter and histogram&lt;/td&gt;
&lt;td&gt;Microsecond&lt;/td&gt;
&lt;td&gt;The socket write round trip time (RTT) counter.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Connect&lt;/td&gt;
&lt;td&gt;Counter and histogram&lt;/td&gt;
&lt;td&gt;Millisecond&lt;/td&gt;
&lt;td&gt;The socket connect/accept with another server/client counter.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Close&lt;/td&gt;
&lt;td&gt;Counter and histogram&lt;/td&gt;
&lt;td&gt;Millisecond&lt;/td&gt;
&lt;td&gt;The socket with other socket counter.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Retransmit&lt;/td&gt;
&lt;td&gt;Counter&lt;/td&gt;
&lt;td&gt;Millisecond&lt;/td&gt;
&lt;td&gt;The socket retransmit package counter.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Drop&lt;/td&gt;
&lt;td&gt;Counter&lt;/td&gt;
&lt;td&gt;Millisecond&lt;/td&gt;
&lt;td&gt;The socket drop package counter.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;demo&#34;&gt;Demo&lt;/h2&gt;
&lt;p&gt;In this section, we demonstrate how to perform network profiling in the
service mesh. To follow along, you will need a running Kubernetes
environment.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; All commands and scripts are available &lt;a href=&#34;https://github.com/mrproliu/skywalking-network-profiling-demo&#34;&gt;in this GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;install-istio&#34;&gt;Install Istio&lt;/h3&gt;
&lt;p&gt;Istio is the most widely deployed service mesh, and comes with a complete demo application that we can use for testing. To install Istio and the demo application, follow these steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install Istio using the demo configuration profile.&lt;/li&gt;
&lt;li&gt;Label the default namespace, so Istio automatically injects Envoy sidecar proxies when we&amp;rsquo;ll deploy the application.&lt;/li&gt;
&lt;li&gt;Deploy the bookinfo application to the cluster.&lt;/li&gt;
&lt;li&gt;Deploy the traffic generator to generate some traffic to the application.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#0086b3&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#008080&#34;&gt;ISTIO_VERSION&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;1.13.1

&lt;span style=&#34;color:#998;font-style:italic&#34;&gt;# install istio&lt;/span&gt;
istioctl install -y --set &lt;span style=&#34;color:#008080&#34;&gt;profile&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;demo
kubectl label namespace default istio-injection&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;enabled

&lt;span style=&#34;color:#998;font-style:italic&#34;&gt;# deploy the bookinfo applications&lt;/span&gt;
kubectl apply -f https://raw.githubusercontent.com/istio/istio/&lt;span style=&#34;color:#008080&#34;&gt;$ISTIO_VERSION&lt;/span&gt;/samples/bookinfo/platform/kube/bookinfo.yaml
kubectl apply -f https://raw.githubusercontent.com/istio/istio/&lt;span style=&#34;color:#008080&#34;&gt;$ISTIO_VERSION&lt;/span&gt;/samples/bookinfo/networking/bookinfo-gateway.yaml
kubectl apply -f https://raw.githubusercontent.com/istio/istio/&lt;span style=&#34;color:#008080&#34;&gt;$ISTIO_VERSION&lt;/span&gt;/samples/bookinfo/networking/destination-rule-all.yaml
kubectl apply -f https://raw.githubusercontent.com/istio/istio/&lt;span style=&#34;color:#008080&#34;&gt;$ISTIO_VERSION&lt;/span&gt;/samples/bookinfo/networking/virtual-service-all-v1.yaml

&lt;span style=&#34;color:#998;font-style:italic&#34;&gt;# generate traffic&lt;/span&gt;
kubectl apply -f https://raw.githubusercontent.com/mrproliu/skywalking-network-profiling-demo/main/resources/traffic-generator.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;install-skywalking&#34;&gt;Install SkyWalking&lt;/h3&gt;
&lt;p&gt;The following will install the storage, backend, and UI needed for SkyWalking:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/apache/skywalking-kubernetes.git
&lt;span style=&#34;color:#0086b3&#34;&gt;cd&lt;/span&gt; skywalking-kubernetes
&lt;span style=&#34;color:#0086b3&#34;&gt;cd&lt;/span&gt; chart
helm dep up skywalking
helm -n istio-system install skywalking skywalking &lt;span style=&#34;color:#d14&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#d14&#34;&gt;&lt;/span&gt; --set &lt;span style=&#34;color:#008080&#34;&gt;fullnameOverride&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;skywalking &lt;span style=&#34;color:#d14&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#d14&#34;&gt;&lt;/span&gt; --set elasticsearch.minimumMasterNodes&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#099&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#d14&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#d14&#34;&gt;&lt;/span&gt; --set elasticsearch.imageTag&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;7.5.1 &lt;span style=&#34;color:#d14&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#d14&#34;&gt;&lt;/span&gt; --set oap.replicas&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#099&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#d14&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#d14&#34;&gt;&lt;/span&gt; --set ui.image.repository&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;apache/skywalking-ui &lt;span style=&#34;color:#d14&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#d14&#34;&gt;&lt;/span&gt; --set ui.image.tag&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;9.2.0 &lt;span style=&#34;color:#d14&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#d14&#34;&gt;&lt;/span&gt; --set oap.image.tag&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;9.2.0 &lt;span style=&#34;color:#d14&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#d14&#34;&gt;&lt;/span&gt; --set oap.envoy.als.enabled&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0086b3&#34;&gt;true&lt;/span&gt; &lt;span style=&#34;color:#d14&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#d14&#34;&gt;&lt;/span&gt; --set oap.image.repository&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;apache/skywalking-oap-server &lt;span style=&#34;color:#d14&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#d14&#34;&gt;&lt;/span&gt; --set oap.storageType&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;elasticsearch &lt;span style=&#34;color:#d14&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#d14&#34;&gt;&lt;/span&gt; --set oap.env.SW_METER_ANALYZER_ACTIVE_FILES&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#d14&#34;&gt;&amp;#39;network-profiling&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;install-skywalking-rover&#34;&gt;Install SkyWalking Rover&lt;/h3&gt;
&lt;p&gt;SkyWalking Rover is deployed on every node in Kubernetes, and it automatically detects the services in the Kubernetes cluster. The network profiling feature has been released in the version 0.3.0 of SkyWalking Rover. When a network monitoring task is created, the SkyWalking rover sends the data to the SkyWalking backend.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -f https://raw.githubusercontent.com/mrproliu/skywalking-network-profiling-demo/main/resources/skywalking-rover.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;start-the-network-profiling-task&#34;&gt;Start the Network Profiling Task&lt;/h3&gt;
&lt;p&gt;Once all deployments are completed, we must create a network profiling task for a specific instance of the service in the SkyWalking UI.&lt;/p&gt;
&lt;p&gt;To open SkyWalking UI, run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl port-forward svc/skywalking-ui 8080:80 --namespace
istio-system
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Currently, we can select the specific instances that we wish to monitor by clicking the &lt;strong&gt;Data Plane&lt;/strong&gt; item in the Service Mesh panel and the &lt;strong&gt;Service&lt;/strong&gt; item in the &lt;strong&gt;Kubernetes&lt;/strong&gt; panel.&lt;/p&gt;
&lt;p&gt;In the figure below, we have selected an instance with a list of tasks in the network profiling tab. When we click the start button, the SkyWalking Rover starts monitoring this instance&amp;rsquo;s network.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f5.jpg&#34; alt=&#34;Figure 5&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Figure 5&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;done&#34;&gt;Done!&lt;/h3&gt;
&lt;p&gt;After a few seconds, you will see the process topology appear on the right side of the page.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f6.jpg&#34; alt=&#34;Figure 6&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Figure 6&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;When you click on the line between processes, you can see the TCP metrics between the two processes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f7.jpg&#34; alt=&#34;Figure 7&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Figure 7&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this article, we detailed a problem that makes troubleshooting service mesh architectures difficult: lack of context between layers in the network stack. These are the cases when eBPF begins to really help with debugging/productivity when existing service mesh/envoy cannot. Then, we researched how eBPF could be applied to common communication, such as TLS. Finally, we demo the implementation of this process with SkyWalking Rover.&lt;/p&gt;
&lt;p&gt;For now, we have completed the performance analysis for OSI layer 4 (mostly TCP). In the future, we will also introduce the analysis for OSI layer 7 protocols like HTTP.&lt;/p&gt;
&lt;h2 id=&#34;get-started-with-istio&#34;&gt;Get Started with Istio&lt;/h2&gt;
&lt;p&gt;To &lt;a href=&#34;https://istio.tetratelabs.io/&#34;&gt;get started with service mesh today, Tetrate Istio Distro&lt;/a&gt; is the easiest way to install, manage, and upgrade Istio. It provides a vetted upstream distribution of Istio that&amp;rsquo;s tested and optimized for specific platforms by Tetrate plus a CLI that facilitates acquiring, installing, and configuring multiple Istio versions. Tetrate Istio Distro also offers &lt;a href=&#34;https://www.tetrate.io/blog/tetrate-istio-distro-achieves-fips-certification/&#34;&gt;FIPS certified Istio builds&lt;/a&gt; for FedRAMP environments.&lt;/p&gt;
&lt;p&gt;For enterprises that need a unified and consistent way to secure and manage services and traditional workloads across complex, heterogeneous deployment environments, we offer &lt;a href=&#34;https://www.tetrate.io/tetrate-service-bridge/&#34;&gt;Tetrate Service Bridge&lt;/a&gt;, our flagship edge-to-workload application connectivity platform built on Istio and Envoy.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.tetrate.io/contact/&#34;&gt;Contact us to learn more&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;additional-resources&#34;&gt;Additional Resources&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/apache/skywalking&#34;&gt;SkyWalking Github Repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/apache/skywalking-rover&#34;&gt;SkyWalking Rover Github Repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://skywalking.apache.org/docs/skywalking-rover/v0.3.0/readme/&#34;&gt;SkyWalking Rover Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://skywalking.apache.org/blog/2022-07-05-pinpoint-service-mesh-critical-performance-impact-by-using-ebpf/&#34;&gt;Pinpoint Service Mesh Critical Performance impact by using eBPF blog post&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=yUF5qRk4rYY&#34;&gt;Apache SkyWalking with Native eBPF Agent presentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ebpf.io/what-is-ebpf#hook-overview&#34;&gt;eBPF hook overview&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Blog: Scaling with Apache SkyWalking</title>
      <link>/blog/2022-01-24-scaling-with-apache-skywalking/</link>
      <pubDate>Mon, 24 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/2022-01-24-scaling-with-apache-skywalking/</guid>
      <description>
        
        
        &lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;In the Apache SkyWalking ecosystem, the OAP obtains metrics, traces, logs, and event data through SkyWalking Agent, Envoy, or other data sources. Under the gRPC protocol, it transmits data by communicating with a single server node. Only when the connection is broken, the reconnecting policy would be used based on DNS round-robin mode. When new services are added at runtime or the OAP load is kept high due to increased traffic of observed services, the OAP cluster needs to scale out for increased traffic. The load of the new OAP node would be less due to all existing agents having connected to previous nodes. Even without scaling, the load of OAP nodes would be unbalanced, because the agent would keep the connection due to random policy at the booting stage. In these cases, it would become a challenge to keep up the health status of all nodes, and be able to scale out when needed.&lt;/p&gt;
&lt;p&gt;In this article, we mainly discuss how to solve this challenge in SkyWalking.&lt;/p&gt;
&lt;h2 id=&#34;how-to-load-balance&#34;&gt;How to Load Balance&lt;/h2&gt;
&lt;p&gt;SkyWalking mainly uses the gRPC protocol for data transmission, so this article mainly introduces load balancing in the gRPC protocol.&lt;/p&gt;
&lt;h3 id=&#34;proxy-or-client-side&#34;&gt;Proxy Or Client-side&lt;/h3&gt;
&lt;p&gt;Based on the &lt;a href=&#34;https://grpc.io/blog/grpc-load-balancing/&#34;&gt;gRPC official Load Balancing blog&lt;/a&gt;, there are two approaches to load balancing:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Client-side&lt;/strong&gt;: The client perceives multiple back-end services and uses a load-balancing algorithm to select a back-end service for each RPC.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Proxy&lt;/strong&gt;: The client sends the message to the proxy server, and the proxy server load balances the message to the back-end service.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;From the perspective of observability system architecture:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Pros&lt;/th&gt;
&lt;th&gt;Cons&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Client-side&lt;/td&gt;
&lt;td&gt;&lt;li&gt;High performance because of the elimination of extra hop&lt;/li&gt;&lt;/td&gt;
&lt;td&gt;&lt;li&gt;Complex client (cluster awareness, load balancing, health check, etc.)&lt;/li&gt;&lt;li&gt;Ensure each data source to be connected provides complex client capabilities&lt;/li&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Proxy&lt;/td&gt;
&lt;td&gt;&lt;li&gt;Simple Client&lt;/li&gt;&lt;/td&gt;
&lt;td&gt;&lt;li&gt;Higher latency&lt;/li&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We choose Proxy mode for the following reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Observable data is not very time-sensitive, a little latency caused by transmission is acceptable. A little extra hop is acceptable and there is no impact on the client-side.&lt;/li&gt;
&lt;li&gt;As an observability platform, we cannot/should not ask clients to change. They make their own tech decisions and may have their own commercial considerations.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;transmission-policy&#34;&gt;Transmission Policy&lt;/h3&gt;
&lt;p&gt;In the proxy mode, we should determine the transmission path between downstream and upstream.&lt;/p&gt;
&lt;p&gt;Different data protocols require different processing policies. There are two transmission policies:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Synchronous&lt;/strong&gt;: Suitable for protocols that require data exchange in the client, such as SkyWalking Dynamic Configuration Service. This type of protocol provides real-time results.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Asynchronous batch&lt;/strong&gt;: Used when the client doesn’t care about the upstream processing results, but only the transmitted data (e.g., trace report, log report, etc.)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The synchronization policy requires that the proxy send the message to the upstream server when receiving the client message, and synchronously return the response data to the downstream client. Usually, only a few protocols need to use the synchronization policy.&lt;/p&gt;
&lt;p&gt;As shown below, after the client sends the request to the Proxy, the proxy would send the message to the server synchronously. When the proxy receives the result, it returns to the client.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./transmission-policy-synchronous.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The asynchronous batch policy means that the data is sent to the upstream server in batches asynchronously. This policy is more common because most protocols in SkyWalking are primarily based on data reporting. We think using the queue as a buffer could have a good effect. The asynchronous batch policy is executed according to the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The proxy receives the data and wraps it as an Event object.&lt;/li&gt;
&lt;li&gt;An event is added into the queue.&lt;/li&gt;
&lt;li&gt;When the cycle time is reached or when the queue elements reach the fixed number, the elements in the queue will parallel consume and send to the OAP.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The advantage of using queues is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Separate data receiving and sending to reduce the mutual influence.&lt;/li&gt;
&lt;li&gt;The interval quantization mechanism can be used to combine events, which helps to speed up sending events to the OAP.&lt;/li&gt;
&lt;li&gt;Using multi-threaded consumption queue events can make fuller use of network IO.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;As shown below, after the proxy receives the message, the proxy would wrap the message as an event and push it to the queue. The message sender would take batch events from the queue and send them to the upstream OAP.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./transmission-policy-asynchronous.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;routing&#34;&gt;Routing&lt;/h3&gt;
&lt;p&gt;Routing algorithms are used to route messages to a single upstream server node.&lt;/p&gt;
&lt;p&gt;The Round-Robin algorithm selects nodes in order from the list of upstream service nodes. The advantage of this algorithm is that the number of times each node is selected is average. When the size of the data is close to the same, each upstream node can handle the same quantity of data content.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./routing-round-robin.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;With the Weight Round-Robin, each upstream server node has a corresponding routing weight ratio. The difference from Round-Robin is that each upstream node has more chances to be routed according to its weight. This algorithm is more suitable to use when the upstream server node machine configuration is not the same.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./routing-weight-round-robin.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The Fixed algorithm is a hybrid algorithm. It can ensure that the same data is routed to the same upstream server node, and when the upstream server scales out, it still maintains routing to the same node; unless the upstream node does not exist, it will reroute. This algorithm is mainly used in the SkyWalking Meter protocol because this protocol needs to ensure that the metrics of the same service instance are sent to the same OAP node.
The Routing steps are as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Generate a unique identification string based on the data content, as short as possible. The amount of data is controllable.&lt;/li&gt;
&lt;li&gt;Get the upstream node of identity from LRU Cache, and use it if it exists.&lt;/li&gt;
&lt;li&gt;According to the identification, generate the corresponding hash value, and find the upstream server node from the upstream list.&lt;/li&gt;
&lt;li&gt;Save the mapping relationship between the upstream server node and identification to LRU Cache.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The advantage of this algorithm is to bind the data with the upstream server node as much as possible, so the upstream server can better process continuous data. The disadvantage is that it takes up a certain amount of memory space to save the corresponding relationship.&lt;/p&gt;
&lt;p&gt;As shown below, the image is divided into two parts:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The left side represents that the same data content always is routed to the same server node.&lt;/li&gt;
&lt;li&gt;The right side represents the data routing algorithm. Get the number from the data, and use the remainder algorithm to obtain the position.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;./routing-fixed.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;We choose to use a combination of Round-Robin and Fixed algorithm for routing:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The Fixed routing algorithm is suitable for specific protocols, mainly used when passing metrics data to the SkyWalking Meter protocol&lt;/li&gt;
&lt;li&gt;The Round-Robin algorithm is used by default. When the SkyWalking OAP cluster is deployed, the configuration of the nodes needs to be as much the same as possible, so there would be no need to use the Weight Round-Robin algorithm.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;how-to-balance-the-load-balancer-itself&#34;&gt;How to balance the load balancer itself?&lt;/h2&gt;
&lt;p&gt;Proxy still needs to deal with the load balancing problem from client to itself, especially when deploying a Proxy cluster in a production environment.&lt;/p&gt;
&lt;p&gt;There are three ways to solve this problem:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Connection management&lt;/strong&gt;: Use the &lt;code&gt;max_connection&lt;/code&gt; config on the client-side to specify the maximum connection duration of each connection. For more information, please read the &lt;a href=&#34;https://github.com/grpc/proposal/blob/master/A9-server-side-conn-mgt.md&#34;&gt;proposal&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cluster awareness&lt;/strong&gt;: The proxy has cluster awareness, and actively disconnects the connection when the load is unbalanced to allow the client to re-pick up the proxy.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Resource limit+HPA&lt;/strong&gt;: Restrict the connection resource situation of each proxy, and no longer accept new connections when the resource limit is reached. And use the HPA mechanism of Kubernetes to dynamically scale out the number of the proxy.&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Connection management&lt;/th&gt;
&lt;th&gt;Cluster awareness&lt;/th&gt;
&lt;th&gt;Resource Limit+HPA&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Pros&lt;/td&gt;
&lt;td&gt;&lt;li&gt;Simple to use&lt;/li&gt;&lt;/td&gt;
&lt;td&gt;&lt;li&gt;Ensure that the number of connections in each proxy is relatively &lt;/li&gt;&lt;/td&gt;
&lt;td&gt;&lt;li&gt;Simple to use&lt;/li&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cons&lt;/td&gt;
&lt;td&gt;&lt;li&gt;Each client needs to ensure that data is not lost&lt;/li&gt;&lt;li&gt;The client is required to accept GOWAY responses&lt;/li&gt;&lt;/td&gt;
&lt;td&gt;&lt;li&gt;May cause a sudden increase in traffic on some nodes&lt;/li&gt;&lt;li&gt;Each client needs to ensure that data is not lost &lt;/li&gt;&lt;/td&gt;
&lt;td&gt;&lt;li&gt;Traffic will not be particularly balanced in each instance&lt;/li&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We choose Limit+HPA for these reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Easy to config and use the proxy and easy to understand based on basic data metrics.&lt;/li&gt;
&lt;li&gt;No data loss due to broken connection. There is no need for the client to implement any other protocols to prevent data loss, especially when the client is a commercial product.&lt;/li&gt;
&lt;li&gt;The connection of each node in the proxy cluster does not need to be particularly balanced, as long as the proxy node itself is high-performance.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;skywalking-satellite&#34;&gt;SkyWalking-Satellite&lt;/h2&gt;
&lt;p&gt;We have implemented this Proxy in the &lt;a href=&#34;https://github.com/apache/skywalking-satellite&#34;&gt;SkyWalking-Satellite&lt;/a&gt; project. It’s used between Client and SkyWalking OAP, effectively solving the load balancing problem.&lt;/p&gt;
&lt;p&gt;After the system is deployed, the Satellite would accept the traffic from the Client, and the Satellite will perceive all the nodes of the OAP through Kubernetes Label Selector or manual configuration, and load balance the traffic to the upstream OAP node.&lt;/p&gt;
&lt;p&gt;As shown below, a single client still maintains a connection with a single Satellite, Satellite would establish the connection with each OAP, and load balance message to the OAP node.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./skywalking-satellites.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;When scaling Satellite, we need to deploy the &lt;a href=&#34;https://github.com/apache/skywalking-swck&#34;&gt;SWCK&lt;/a&gt; adapter and configure the HPA in Kubernetes. SWCK is a platform for the SkyWalking users, provisions, upgrades, maintains SkyWalking relevant components, and makes them work natively on Kubernetes.&lt;/p&gt;
&lt;p&gt;After deployment is finished, the following steps would be performed:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Read metrics from OAP&lt;/strong&gt;: HPA requests the SWCK metrics adapter to dynamically read the metrics in the OAP.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scaling the Satellite&lt;/strong&gt;: Kubernetes HPA senses that the metrics values are in line with expectations, so the Satellite would be scaling automatically.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;As shown below, use the dotted line to divide the two parts. HPA uses SWCK Adapter to read the metrics in the OAP. When the threshold is met, HPA would scale the Satellite deployment.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;swck-hpa.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;example&#34;&gt;Example&lt;/h2&gt;
&lt;p&gt;In this section, we will demonstrate two cases:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;SkyWalking Scaling: After SkyWalking OAP scaling, the traffic would auto load balancing through Satellite.&lt;/li&gt;
&lt;li&gt;Satellite Scaling: Satellite’s own traffic load balancing.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;NOTE: All commands could be accessed through &lt;a href=&#34;https://github.com/mrproliu/sw-satellite-demo-scripts/tree/1180c23e8f3bb36778307f9ae15395274ca039b3&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;skywalking-scaling&#34;&gt;SkyWalking Scaling&lt;/h3&gt;
&lt;p&gt;We will use the &lt;a href=&#34;https://istio.io/latest/docs/examples/bookinfo/&#34;&gt;bookinfo application&lt;/a&gt; to demonstrate how to integrate Apache SkyWalking 8.9.1 with Apache SkyWalking-Satellite 0.5.0, and observe the service mesh through the Envoy ALS protocol.&lt;/p&gt;
&lt;p&gt;Before starting, please make sure that you already have a Kubernetes environment.&lt;/p&gt;
&lt;h4 id=&#34;install-istio&#34;&gt;Install Istio&lt;/h4&gt;
&lt;p&gt;Istio provides a very convenient way to configure the Envoy proxy and enable the access log service. The following step:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install the istioctl locally to help manage the Istio mesh.&lt;/li&gt;
&lt;li&gt;Install Istio into the Kubernetes environment with a demo configuration profile, and enable the Envoy ALS. Transmit the ALS message to the satellite. The satellite we will deploy later.&lt;/li&gt;
&lt;li&gt;Add the label into the default namespace so Istio could automatically inject Envoy sidecar proxies when you deploy your application later.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#998;font-style:italic&#34;&gt;# install istioctl&lt;/span&gt;
&lt;span style=&#34;color:#0086b3&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#008080&#34;&gt;ISTIO_VERSION&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;1.12.0
curl -L https://istio.io/downloadIstio | sh - 
sudo mv &lt;span style=&#34;color:#008080&#34;&gt;$PWD&lt;/span&gt;/istio-&lt;span style=&#34;color:#008080&#34;&gt;$ISTIO_VERSION&lt;/span&gt;/bin/istioctl /usr/local/bin/

&lt;span style=&#34;color:#998;font-style:italic&#34;&gt;# install istio&lt;/span&gt;
istioctl install -y --set &lt;span style=&#34;color:#008080&#34;&gt;profile&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;demo &lt;span style=&#34;color:#d14&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#d14&#34;&gt;&lt;/span&gt;	--set meshConfig.enableEnvoyAccessLogService&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0086b3&#34;&gt;true&lt;/span&gt; &lt;span style=&#34;color:#d14&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#d14&#34;&gt;&lt;/span&gt;	--set meshConfig.defaultConfig.envoyAccessLogService.address&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;skywalking-system-satellite.skywalking-system:11800

&lt;span style=&#34;color:#998;font-style:italic&#34;&gt;# enbale envoy proxy in default namespace&lt;/span&gt;
kubectl label namespace default istio-injection&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;enabled
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;install-swck&#34;&gt;Install SWCK&lt;/h4&gt;
&lt;p&gt;SWCK provides convenience for users to deploy and upgrade SkyWalking related components based on Kubernetes. The automatic scale function of Satellite also mainly relies on SWCK. For more information, you could refer to the &lt;a href=&#34;https://github.com/apache/skywalking-swck/blob/master/docs/operator.md#guides-of-operator-deployment&#34;&gt;official documentation&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#998;font-style:italic&#34;&gt;# Install cert-manager&lt;/span&gt;
kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.3.1/cert-manager.yaml

&lt;span style=&#34;color:#998;font-style:italic&#34;&gt;# Deploy SWCK&lt;/span&gt;
mkdir -p skywalking-swck &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#0086b3&#34;&gt;cd&lt;/span&gt; skywalking-swck
wget https://dlcdn.apache.org/skywalking/swck/0.6.1/skywalking-swck-0.6.1-bin.tgz
tar -zxvf skywalking-swck-0.6.1-bin.tgz
&lt;span style=&#34;color:#0086b3&#34;&gt;cd&lt;/span&gt; config
kubectl apply -f operator-bundle.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;deploy-apache-skywalking-and-apache-skywalking-satellite&#34;&gt;Deploy Apache SkyWalking And Apache SkyWalking-Satellite&lt;/h4&gt;
&lt;p&gt;We have provided a simple script to deploy the skywalking OAP, UI, and Satellite.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#998;font-style:italic&#34;&gt;# Create the skywalking components namespace&lt;/span&gt;
kubectl create namespace skywalking-system
kubectl label namespace skywalking-system swck-injection&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;enabled
&lt;span style=&#34;color:#998;font-style:italic&#34;&gt;# Deploy components&lt;/span&gt;
kubectl apply -f https://raw.githubusercontent.com/mrproliu/sw-satellite-demo-scripts/5821a909b647f7c8f99c70378e197630836f45f7/resources/sw-components.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;deploy-bookinfo-application&#34;&gt;Deploy Bookinfo Application&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#0086b3&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#008080&#34;&gt;ISTIO_VERSION&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;1.12.0
kubectl apply -f https://raw.githubusercontent.com/istio/istio/&lt;span style=&#34;color:#008080&#34;&gt;$ISTIO_VERSION&lt;/span&gt;/samples/bookinfo/platform/kube/bookinfo.yaml
kubectl &lt;span style=&#34;color:#0086b3&#34;&gt;wait&lt;/span&gt; --for&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#008080&#34;&gt;condition&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;Ready pods --all --timeout&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;1200s
kubectl port-forward service/productpage &lt;span style=&#34;color:#099&#34;&gt;9080&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Next, please open your browser and visit &lt;code&gt;http://localhost:9080&lt;/code&gt;. You should be able to see the Bookinfo application. Refresh the webpage several times to generate enough access logs.&lt;/p&gt;
&lt;p&gt;Then, you can see the topology and metrics of the Bookinfo application on SkyWalking WebUI. At this time, you can see that the Satellite is working!&lt;/p&gt;
&lt;h4 id=&#34;deploy-monitor&#34;&gt;Deploy Monitor&lt;/h4&gt;
&lt;p&gt;We need to install OpenTelemetry Collector to collect metrics in OAPs and analyze them.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#998;font-style:italic&#34;&gt;# Add OTEL collector&lt;/span&gt;
kubectl apply -f https://raw.githubusercontent.com/mrproliu/sw-satellite-demo-scripts/5821a909b647f7c8f99c70378e197630836f45f7/resources/otel-collector-oap.yaml

kubectl port-forward -n skywalking-system  service/skywalking-system-ui 8080:80
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Next, please open your browser and visit &lt;code&gt;http://localhost:8080/&lt;/code&gt; and create a new item on the dashboard. The SkyWalking Web UI pictured below shows how the data content is applied.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./mesh-count-conf.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;scaling-oap&#34;&gt;Scaling OAP&lt;/h4&gt;
&lt;p&gt;Scaling the number of OAPs by deployment.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl scale --replicas&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#099&#34;&gt;3&lt;/span&gt; -n skywalking-system deployment/skywalking-system-oap
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;done&#34;&gt;Done!&lt;/h4&gt;
&lt;p&gt;After a period of time, you will see that the number of OAPs becomes 3, and the ALS traffic is balanced to each OAP.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./mesh-count-list.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;satellite-scaling&#34;&gt;Satellite Scaling&lt;/h3&gt;
&lt;p&gt;After we have completed the SkyWalking Scaling, we would carry out the Satellite Scaling demo.&lt;/p&gt;
&lt;h4 id=&#34;deploy-swck-hpa&#34;&gt;Deploy SWCK HPA&lt;/h4&gt;
&lt;p&gt;SWCK provides an adapter to implement the Kubernetes external metrics to adapt the HPA through reading the metrics in SkyWalking OAP. We expose the metrics service in Satellite to OAP and configure HPA Resource to auto-scaling the Satellite.&lt;/p&gt;
&lt;p&gt;Install the SWCK adapter into the Kubernetes environment:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl apply -f skywalking-swck/config/adapter-bundle.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Create the HPA resource, and limit each Satellite to handle a maximum of 10 connections:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl apply -f https://raw.githubusercontent.com/mrproliu/sw-satellite-demo-scripts/5821a909b647f7c8f99c70378e197630836f45f7/resources/satellite-hpa.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then, you could see we have 9 connections in one satellite. One envoy proxy may establish multiple connections to the satellite.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ kubectl get HorizontalPodAutoscaler -n skywalking-system
NAME       REFERENCE                                TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
hpa-demo   Deployment/skywalking-system-satellite   9/10      &lt;span style=&#34;color:#099&#34;&gt;1&lt;/span&gt;         &lt;span style=&#34;color:#099&#34;&gt;3&lt;/span&gt;         &lt;span style=&#34;color:#099&#34;&gt;1&lt;/span&gt;          5m18s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;scaling-application&#34;&gt;Scaling Application&lt;/h4&gt;
&lt;p&gt;The scaling application could establish more connections to the satellite, to verify whether the HPA is in effect.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl scale --replicas&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#099&#34;&gt;3&lt;/span&gt; deployment/productpage-v1 deployment/details-v1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;done-1&#34;&gt;Done!&lt;/h4&gt;
&lt;p&gt;By default, Satellite will deploy a single instance and a single instance will only accept 11 connections. HPA resources limit one Satellite to handle 10 connections and use a stabilization window to make Satellite stable scaling up. In this case, we deploy the Bookinfo application in 10+ instances after scaling, which means that 10+ connections will be established to the Satellite.&lt;/p&gt;
&lt;p&gt;So after HPA resources are running, the Satellite would be automatically scaled up to 2 instances. You can learn about the calculation algorithm of replicas through the &lt;a href=&#34;https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details&#34;&gt;official documentation&lt;/a&gt;. Run the following command to view the running status:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ kubectl get HorizontalPodAutoscaler -n skywalking-system --watch
NAME       REFERENCE                                TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
hpa-demo   Deployment/skywalking-system-satellite   11/10     &lt;span style=&#34;color:#099&#34;&gt;1&lt;/span&gt;         &lt;span style=&#34;color:#099&#34;&gt;3&lt;/span&gt;         &lt;span style=&#34;color:#099&#34;&gt;1&lt;/span&gt;          3m31s
hpa-demo   Deployment/skywalking-system-satellite   11/10     &lt;span style=&#34;color:#099&#34;&gt;1&lt;/span&gt;         &lt;span style=&#34;color:#099&#34;&gt;3&lt;/span&gt;         &lt;span style=&#34;color:#099&#34;&gt;1&lt;/span&gt;          4m20s
hpa-demo   Deployment/skywalking-system-satellite   11/10     &lt;span style=&#34;color:#099&#34;&gt;1&lt;/span&gt;         &lt;span style=&#34;color:#099&#34;&gt;3&lt;/span&gt;         &lt;span style=&#34;color:#099&#34;&gt;2&lt;/span&gt;          4m38s
hpa-demo   Deployment/skywalking-system-satellite   11/10     &lt;span style=&#34;color:#099&#34;&gt;1&lt;/span&gt;         &lt;span style=&#34;color:#099&#34;&gt;3&lt;/span&gt;         &lt;span style=&#34;color:#099&#34;&gt;2&lt;/span&gt;          5m8s
hpa-demo   Deployment/skywalking-system-satellite   6/10      &lt;span style=&#34;color:#099&#34;&gt;1&lt;/span&gt;         &lt;span style=&#34;color:#099&#34;&gt;3&lt;/span&gt;         &lt;span style=&#34;color:#099&#34;&gt;2&lt;/span&gt;          5m23s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;By observing the “number of connections” metric, we would be able to see that when the number of connections of each gRPC exceeds 10 connections, then the satellite automatically scales through the HPA rule. As a result, the connection number is down to normal status (in this example, less than 10)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;swctl metrics linear --name satellite_service_grpc_connect_count --service-name satellite::satellite-service
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;satellite-connection-metrics.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Blog: SkyWalking performance in Service Mesh scenario</title>
      <link>/blog/2019-01-25-mesh-loadtest/</link>
      <pubDate>Fri, 25 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019-01-25-mesh-loadtest/</guid>
      <description>
        
        
        &lt;ul&gt;
&lt;li&gt;Author: Hongtao Gao, Apache SkyWalking &amp;amp; ShardingShpere PMC&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hanahmily&#34;&gt;GitHub&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/hanahmily&#34;&gt;Twitter&lt;/a&gt;, &lt;a href=&#34;https://www.linkedin.com/in/gao-hongtao-47b835168/&#34;&gt;Linkedin&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Service mesh receiver was first introduced in Apache SkyWalking 6.0.0-beta. It is designed to provide a common entrance for receiving telemetry data from service mesh framework, for instance, Istio, Linkerd, Envoy etc. What’s the service mesh? According to Istio’s explain:&lt;/p&gt;
&lt;p&gt;The term service mesh is used to describe the network of microservices that make up such applications and the interactions between them.&lt;/p&gt;
&lt;p&gt;As a PMC member of Apache SkyWalking, I tested trace receiver and well understood the performance of collectors in trace scenario. I also would like to figure out the performance of service mesh receiver.&lt;/p&gt;
&lt;h2 id=&#34;different-between-trace-and-service-mesh&#34;&gt;Different between trace and service mesh&lt;/h2&gt;
&lt;p&gt;Following chart presents a typical trace map:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;image5.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;You could find a variety of elements in it just like web service, local method, database, cache, MQ and so on. But service mesh only collect service network telemetry data that contains the entrance and exit data of a service for now(more elements will be imported soon, just like Database). A smaller quantity of data is sent to the service mesh receiver than the trace.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;image1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;But using sidecar is a little different.The client requesting “A” that will send a segment to service mesh receiver from “A”’s sidecar. If “A” depends on “B”,  another segment will be sent from “A”’s sidecar. But for a trace system, only one segment is received by the collector. The sidecar model splits one segment into small segments, that will increase service mesh receiver network overhead.&lt;/p&gt;
&lt;h2 id=&#34;deployment-architecture&#34;&gt;Deployment Architecture&lt;/h2&gt;
&lt;p&gt;In this test, I will pick two different backend deployment. One is called mini unit, consist of one collector and one elasticsearch instance. Another is a standard production cluster, contains three collectors and three elasticsearch instances.&lt;/p&gt;
&lt;p&gt;Mini unit is a suitable architecture for dev or test environment. It saves your time and VM resources, speeds up depolyment process.&lt;/p&gt;
&lt;p&gt;The standard cluster provides good performance and HA for a production scenario. Though you will pay more money and take care of the cluster carefully, the reliability of the cluster will be a good reward to you.&lt;/p&gt;
&lt;p&gt;I pick 8 CPU and 16GB VM to set up the test environment. This test targets the performance of normal usage scenarios, so that choice is reasonable. The cluster is built on Google Kubernetes Engine(GKE), and every node links each other with a VPC network. For running collector is a CPU intensive task, the resource request of collector deployment should be 8 CPU, which means every collector instance occupy a VM node.&lt;/p&gt;
&lt;h2 id=&#34;testing-process&#34;&gt;Testing Process&lt;/h2&gt;
&lt;p&gt;Receiving mesh fragments per second(MPS) depends on the following variables.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Ingress query per second(QPS)&lt;/li&gt;
&lt;li&gt;The topology of a microservice cluster&lt;/li&gt;
&lt;li&gt;Service mesh mode(proxy or sidecar)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this test, I use Bookinfo app as a demo cluster.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;image6.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;So every request will touch max 4 nodes. Plus picking the sidecar mode(every request will send two telemetry data),  the MPS will be QPS * 4 *2.&lt;/p&gt;
&lt;p&gt;There are also some important metrics that should be explained&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Client Query Latency: GraphQL API query response time heatmap.&lt;/li&gt;
&lt;li&gt;Client Mesh Sender: Send mesh segments per second. The total line represents total send amount and the error line is the total number of failed send.&lt;/li&gt;
&lt;li&gt;Mesh telemetry latency: service mesh receiver handling data heatmap.&lt;/li&gt;
&lt;li&gt;Mesh telemetry received: received mesh telemetry data per second.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;mini-unit&#34;&gt;Mini Unit&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;image3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;You could find collector can process up to &lt;strong&gt;25k&lt;/strong&gt; data per second. The CPU usage is about 4 cores. Most of the query latency is less than 50ms. After login the VM on which collector instance running, I know that system load is reaching the limit(max is 8).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;image2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;According to the previous formula, a single collector instance could process &lt;strong&gt;3k&lt;/strong&gt; QPS of Bookinfo traffic.&lt;/p&gt;
&lt;h3 id=&#34;standard-cluster&#34;&gt;Standard Cluster&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;image4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Compare to the mini-unit, cluster’s throughput increases linearly. Three instances provide total 80k per second processing power. Query latency increases slightly, but it’s also very small(less than 500ms). I also checked every collector instance system load that all reached the limit. 10k QPS of BookInfo telemetry data could be processed by the cluster.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Let’s wrap them up. There are some important things you could get from this test.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;QPS varies by the there variables. The test results in this blog are not important. The user should pick property value according to his system.&lt;/li&gt;
&lt;li&gt;Collector cluster’s processing power could scale out.&lt;/li&gt;
&lt;li&gt;The collector is CPU intensive application. So you should provide sufficient CPU resource to it.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This blog gives people a common method to evaluate the throughput of Service Mesh Receiver. Users could use this to design their Apache Skywalking backend deployment architecture.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
